# í…ì„œì†Œê°œ


```python
import tensorflow as tf
import numpy as np
```

í…ì„œëŠ” ì¼ê´€ëœ ìœ í˜•ì„ ê°€ì§„ ë‹¤ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. ëª¨ë“  dtypesëŠ” tf.dtypes.DTypeì—ì„œ ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Numpyì— ë” ìµìˆ™í•˜ë‹¤ë©´ , í…ì„œëŠ” np.arraysì™€ ê°™ìŠµë‹ˆë‹¤.
ëª¨ë“  í…ì„œëŠ” Python ìˆ«ì ë° ë¬¸ìì—´ë¡œ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ì„œì˜ ë‚´ìš©ì„ ì—…í…Œì´íŠ¸ í•  ìˆ˜ ì—†ê³ , ìƒˆë¡œìš´ í…ì„œë¥¼ ë§Œë“¤ìˆ˜ë§Œ ìˆìŠµë‹ˆë‹¤.

## ê¸°ì´ˆ


"ìŠ¤ì¹¼ë¼" ë˜ëŠ” "ë­í¬-0" ì˜ í…ì„œì…ë‹ˆë‹¤. ìŠ¤ì¹¼ë¼ëŠ” ë‹¨ì¼ê°’ì„ í¬í•¨í•˜ê³  ì¶•ì€ ì—†ìŠµë‹ˆë‹¤.


```python
# This will be an int32 tensor by default; see "dtypes" below.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
```

"ë²¡í„°" ë˜ëŠ” "ë­í¬-1"ì˜ í…ì„œì…ë‹ˆë‹¤. ë²¡í„°ëŠ” í•˜ë‚˜ì˜ ì¶•ì´ ì¡´ì¬í•©ë‹ˆë‹¤.


```python
# Let's make this a float tensor.
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

"í–‰ë ¬"ë˜ëŠ” "ë­í¬-2"ì˜ í…ì„œëŠ” ë‘ê°œì˜ ì¶•ì´ ì¡´ì¬í•©ë‹ˆë‹¤.


```python
# If you want to be specific, you can set the dtype (see below) at creation time
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
```

<table>
<tr>
  <th>A scalar, shape: <code>[]</code></th>
  <th>A vector, shape: <code>[3]</code></th>
  <th>A matrix, shape: <code>[3, 2]</code></th>
</tr>
<tr>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/scalar.png?raw=1" alt="A scalar, the number 4" />
  </td>

  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/vector.png?raw=1" alt="The line with 3 sections, each one containing a number."/>
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/matrix.png?raw=1" alt="A 3x2 grid, with each cell containing a number.">
  </td>
</tr>
</table>


í…ì„œëŠ” ë” ë§ì€ ì¶•ì´ ì¡´ì¬ í• ìˆ˜ ìˆê³ , ë°‘ì€ 3ê°œì˜ ì¶•ì´ ìˆëŠ” í…ì„œì…ë‹ˆë‹¤.


```python
# There can be an arbitrary number of
# axes (sometimes called "dimensions")
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)
```

ì¶•ì´ 2ê°œ ì´ìƒì¸ í…ì„œëŠ” ì‹œê°í™”ë¥¼ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ë‹¤ì–‘í•©ë‹ˆë‹¤.

<table>
<tr>
  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>
<tr>
<tr>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_numpy.png?raw=1"/>
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_front.png?raw=1"/>
  </td>

  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_block.png?raw=1"/>
  </td>
</tr>

</table>

í…ì„œë¥¼ np.array , tensor.numpy ë©”ì„œë“œë¥¼ ì´ìš©í•˜ì—¬ì„œ numpyë°°ì—´ë¡œ ë³€í™˜í• ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
#
np.array(rank_2_tensor)
```


```python
#
rank_2_tensor.numpy()
```

í…ì„œëŠ” float ë° intë¥¼ í¬í•¨í•˜ì§€ë§Œ ë‹¤ìŒì„ ë¹„ë¡¯í•œ ë§ì€ ìœ í˜•ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
 ë³µì†Œìˆ˜, ë¬¸ìì—´
 ê¸°ë³¸ tf.Tensor í´ë˜ìŠ¤ì—ì„œ í…ì„œëŠ” ì§ì‚¬ê°í˜• ì…ë‹ˆë‹¤. 
 ê° ì¶•ì„ ë”°ë¼ ëª¨ë“  ìš”ì†Œì˜ í¬ê¸°ê°€ ë™ì¼í•´ì•„í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¤ì–‘í•œ ëª¨ë¦¬ë¥¼ ì²˜ë¦¬í• ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜í•œ ìœ í˜•ì˜ í…ì„œê°€ ìˆìŠµë‹ˆë‹¤.
  -ë¹„ì •í˜• í…ì„œ
  -í¬ì†Œ í…ì„œ

ë§ì…ˆ, ìš”ì†Œë³„ ê³±ì…ˆ ë° í–‰ë ¬ ê³±ì…ˆì„ í¬í•¨í•˜ì—¬ í…ì„œì— ëŒ€í•œ ìˆ˜í•™ì„ ìˆ˜í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.


```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2])`

print(tf.add(a, b), "\n")
print(tf.multiply(a, b), "\n")
print(tf.matmul(a, b), "\n")
```


```python
print(a + b, "\n") # element-wise addition
print(a * b, "\n") # element-wise multiplication
print(a @ b, "\n") # matrix multiplication
```

í…ì„œëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ì—°ì‚°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.


```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
# Find the index of the largest value
print(tf.argmax(c))
# Compute the softmax
print(tf.nn.softmax(c))
```

## ëª¨ì–‘ ì •ë³´

í…ì„œì—ëŠ” ëª¨ì–‘ì´ ìˆìŠµë‹ˆë‹¤. 
 -Shape : í…ì„œì­ ê° ì¶•ì˜ ê¸¸ì´
 -Rank: ìœ„ì—ì„œ ë‚˜íƒ€ëƒ‡ë“¯ì´ í…ì„œ ì¶•ì˜ ìˆ˜, ìŠ¤ì¹¼ë¼ëŠ” 0ìˆœìœ„, ë²¡í„°ëŠ” 1ìˆœìœ„, í–‰ë ¬ì€ 2ìˆœìœ„
 -ì¶• ë˜ëŠ” ì°¨ì› : í…ì„œì˜ íŠ¹ì • ì°¨ì›
 -í¬ê¸°: í…ì„œì˜ ì´ í•­ëª© ìˆ˜, ì œí’ˆ ëª¨ì–‘ ë²¡í„°

í…ì„œì™€ tf.TensorShape ê°ì²´ëŠ” í¸ë¦¬í•œ ì†ì„±ì´ ìˆìŠµë‹ˆë‹¤.


```python
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

<table>
<tr>
  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape.png?raw=1" alt="A tensor shape is like a vector.">
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/4-axis_block.png?raw=1" alt="A 4-axis tensor">
  </td>
  </tr>
</table>



```python
print("Type of every element:", rank_4_tensor.dtype)
print("Number of axes:", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())
```

ì¶•ì€ ì¸ë±ìŠ¤ë¡œ ì°¸ì¡°ë˜ì§€ë§Œ ê°ê° ì˜ë¯¸ë¥¼ ì¶”ì í•´ì•¼ í•©ë‚˜ë””.ì¶•ì€ ì „ì—­ì—ì„œ ë¡œì»¬ë¡œ ì •ë ¬ë©ë‹ˆë‹¤. ë°°ì¹˜ì¶•ì´ ë¨¼ì €ì´ê³  ê³µê°„ ì°¨ì›ì´ ë‹¤ìŒì— ì˜¤ê³ , ê° ìœ„ì¹˜ì— ëŒ€í•œ ê¸°ëŠ¥ì´
ë§ˆì§€ë§‰ì— ì˜µë‹ˆë‹¤. ì´ëŸ°ì‹ìœ¼ë¡œ íŠ¹ì§• ë²¡í„°ëŠ” ë©”ëª¨ë¦¬ì˜ ì—°ì†ì˜ì—­ì…ë‹ˆë‹¤.

<table>
<tr>
<th>Typical axis order</th>
</tr>
<tr>
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape2.png?raw=1" alt="Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Features">
  </td>
</tr>
</table>

## ì¸ë±ì‹±

### ë‹¨ì¼ ì¶• ì¸ë±ì‹±

í…ì„œí”Œë¡œìš°ëŠ” íŒŒì´ì¬ì˜ [ëª©ë¡ë˜ëŠ” ë¬¸ìì—´ ì¸ë±ì‹±](https://docs.python.org/3/tutorial/introduction.html#strings)ê³¼ ìœ ì‚¬í•œ í‘œì¤€ íŒŒì´ì¬ ì¸ë±ì‹± ê·œì¹™ ë° Numpy ì¸ë±ì‹±ì˜ ê¸°ë³¸ ê·œì¹™ì„ ë”°ë¦…ë‹ˆë‹¤.


- ì¸ë±ìŠ¤ ì‹œì‘ì€ 0
- ìŒìˆ˜ ì¸ë±ìŠ¤ëŠ” ëì—ì„œ ê±°ê¾¸ë¡œ ê³„ì‚°
- ì½œë¡  : ì€ ìŠ¬ë¼ì´ìŠ¤ì—ì„œ ì‚¬ìš©. start:stop:step



```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
```

ìŠ¤ì¹¼ë¼ë¡œ ì¸ë±ì‹±ì„ í•˜ë©´ ì¶•ì´ ì œê±° ë©ë‹ˆë‹¤.


```python
print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())
```

: ìŠ¬ë¼ì´ìŠ¤ë¡œ ì¸ë±ì‹±ì„ í•˜ë©´ ì¶•ì´ ìœ ì§€ ë©ë‹ˆë‹¤.


```python
print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())
```

### ë‹¤ì¶• ì¸ë±ì‹±

ìƒìœ„ í…ì„œëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¥¼ ì „ë‹¬í•˜ì—¬ ì¸ë±ì‹±ë©ë‹ˆë‹¤.
ë‹¨ì¼ ì¶•ì˜ ê²½ìš°ì™€ ë˜‘ê°™ì€ ê·œì¹™ì´ ê° ì¶•ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.


```python
print(rank_2_tensor.numpy())
```

ê° ì¸ë±ìŠ¤ì— ì •ìˆ˜ë¥¼ ì „ë‹¬í•˜ê²Œ ë˜ë©´ ê²°ê³¼ëŠ” ìŠ¤ì¹¼ë¼ì…ë‹ˆë‹¤.


```python
# Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())
```

ì •ìˆ˜ì™€ ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì¡°í•©í•˜ì—¬ ì¸ë±ì‹±ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# Get row and column tensors
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")
```

ë°‘ì˜ ë‚´ìš©ì€ 3ì¶• í…ì„œë¥¼ ì‚¬ìš©í•œ ì˜ˆì‹œì…ë‹ˆë‹¤.


```python
print(rank_3_tensor[:, :, 4])
```

<table>
<tr>
<th colspan=2>Selecting the last feature across all locations in each example in the batch </th>
</tr>
<tr>
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index1.png?raw=1" alt="A 3x2x5 tensor with all the values at the index-4 of the last axis selected.">
  </td>
      <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index2.png?raw=1" alt="The selected values packed into a 2-axis tensor.">
  </td>
</tr>
</table>

## í˜•ìƒ ì¡°ì‘í•˜ê¸°


```python
# Shape returns a `TensorShape` object that shows the size along each axis
x = tf.constant([[1], [2], [3]])
print(x.shape)
```


```python
# You can convert this object into a Python list, too
print(x.shape.as_list())
```

í…ì„œë¥¼ ìƒˆë¡œìš´ í˜•íƒœë¡œ ë³€í˜• ê°€ëŠ¥í•©ë‹ˆë‹¤. tf.reshape ê¸°ë³¸ ë°ì´í„°ê°€ ì¤‘ë³µ ë  í•„ìš”ê°€ ì—†ê¸° ë•Œë¬¸ì— ì‘ì—…ì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# You can reshape a tensor to a new shape.
# Note that you're passing in a list
reshaped = tf.reshape(x, [1, 3])
```


```python
print(x.shape)
print(reshaped.shape)
```

ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ì—ì„œ ë ˆì´ì•„ì›ƒì„ ìœ ì§€, ë™ì¼í•œ ë°ì´í„°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ìš”ì²­ëœ ëª¨ì–‘ìœ¼ë¡œ ìƒˆë¡œìš´ í…ì„œê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
í…ì„œí”Œë¡œìš°ëŠ” CìŠ¤íƒ€ì¼ì˜ "í–‰ ì¤‘ì‹¬"ë©”ëª¨ë¦¬ ìˆœì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê°€ì¥ ì˜¤ë¥¸ìª½ ì¸ë±ìŠ¤ë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ë©”ëª¨ë¦¬ì˜ ë‹¨ì¼ ë‹¨ê³„ì— í•´ë‹¹í•©ë‹ˆë‹¤


```python
print(rank_3_tensor)
```

í…ì„œë¥¼ í‰ë©´í™”í•˜ë©´ ë©”ëª¨ë¦¬ì— ì–´ë–¤ ìˆœì„œë¡œ ë°°ì¹˜ë˜ìˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# A `-1` passed in the `shape` argument says "Whatever fits".
print(tf.reshape(rank_3_tensor, [-1]))
```

tf.reshapeì˜ ê°€ì¥ ì¢‹ì€ ìš©ë„ëŠ” ì¸ì ‘í•œ ì¶•ì„ ê²°í•©í•˜ê±°ë‚˜ ë¶„í• í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
3*2*5 í…ì„œì˜ ê²½ìš°, ìŠ¬ë¼ì´ìŠ¤ê°€ í˜¼í•©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ (3*2)*5 ë˜ëŠ”  3*(2*5)ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì…ë‹ˆë‹¤.


```python
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n")
print(tf.reshape(rank_3_tensor, [3, -1]))
```

<table>
<th colspan=3>
Some good reshapes.
</th>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-before.png?raw=1" alt="A 3x2x5 tensor">
  </td>
  <td>
  <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good1.png?raw=1" alt="The same data reshaped to (3x2)x5">
  </td>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good2.png?raw=1" alt="The same data reshaped to 3x(2x5)">
  </td>
</tr>
</table>


í˜•ìƒì„ ë³€ê²½í•˜ë©´ ì´ ìš”ì†Œ ìˆ˜ë¥¼ ê°–ëŠ” ìƒˆë¡œìš´ í˜•ìƒì— ì˜í•´ ì‘ë™í•˜ì§€ë§Œ, ì¶•ì˜ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì§€ ì•Šìœ¼ë©´ ì‚¬ìš©ê°€ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.
tf.reshapeì—ì„œ ì¶• êµí™˜ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, tf.transposeë¥¼ ì‚¬ìš©í•˜ì—¬ì•¼í•©ë‹ˆë‹¤.


```python
# Bad examples: don't do this

# You can't reorder axes with reshape.
print(tf.reshape(rank_3_tensor, [2, 3, 5]), "\n") 

# This is a mess
print(tf.reshape(rank_3_tensor, [5, 6]), "\n")

# This doesn't work at all
try:
  tf.reshape(rank_3_tensor, [7, -1])
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

<table>
<th colspan=3>
Some bad reshapes.
</th>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad.png?raw=1" alt="You can't reorder axes, use tf.transpose for that">
  </td>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad4.png?raw=1" alt="Anything that mixes the slices of data together is probably wrong.">
  </td>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-bad2.png?raw=1" alt="The new shape must fit exactly.">
  </td>
</tr>
</table>

ì™„ì „íˆ ì§€ì •ë˜ì§€ ì•Šì€ í˜•ìƒ ì „ì²´ì— ê±¸ì³ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. Noneì´ í¬í•¨ë˜ê±°ë‚˜ ì „ì²´ í˜•ìƒì´ Noneì…ë‹ˆë‹¤.

##  DTypesì— ëŒ€í•œ ì¶”ê°€ ì •ë³´

tf.Tensorì˜ ë°ì´í„° ìœ í˜•ì„ ê²€ì‚¬í•˜ë ¤ë©´, Tensor.dtypeì˜ ì†ì„±ì„ ì‚¬ìš©
íŒŒì´ì¬ ê°ì²´ì—ì„œ tf.Tensorë¥¼ ë§Œë“¤ë•Œ ì„ íƒì ìœ¼ë¡œ ë°ì´í„° ìœ í˜•ì„ ì§€ì •ê°€ëŠ¥í•©ë‹ˆë‹¤.

ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, í…ì„œí”Œë¡œìš°ëŠ” ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¼ìˆ˜ ìˆëŠ” ë°ì´í„° ìœ í˜•ì„ ì„ íƒí•˜ê²Œ ë©ë‹ˆë‹¤.
í…ì„œí”Œë¡œìš°ëŠ” íŒŒì´ì„  ì •ìˆ˜ë¥¼ tf.int32ë¡œ íŒŒì´ì¬ ë¶€ë™ ì†Œìˆ˜ì ì„ tf.float32ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
ê·¸ë ‡ì§€ í…ì„œí”Œë¡œìš°ëŠ” Numpyê°€ ë°°ì—´ë¡œ ë³€í™˜í• ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê·œì¹™ì„ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.


```python
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
# Now, cast to an uint8 and lose the decimal precision
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
```

## ë¸Œë¡œë“œìºìŠ¤íŒ…

ë¸Œë¡œë“œìºìŠ¤íŒ…ì€ Numpyì˜ í•´ë‹¹íŠ¹ì„±ì—ì„œ ê°€ì ¸ì˜¨ ê°œë…ì…ë‹ˆë‹¤. íŠ¹ì • ì¡°ê±´ì—ì„œ ì‘ì€ í…ì„œëŠ” ê²°í•©ëœ ì—°ì‚°ì„ ì‹¤í–‰í•  ë•Œ ë” í° í…ì„œì— ë§ê²Œ ìë™ìœ¼ë¡œ í™•ì¥ë©ë‹ˆë‹¤.
ê°€ì¥ ê°„ë‹¨í•˜ê³  ì¼ë°˜ì ì¸ ê²½ìš°ëŠ” ìŠ¤ì¹¼ë¼ì— í…ì„œë¥¼ ê³±í•˜ê¸° í•˜ê±°ë‚˜ ì¶”ê°€í• ë•Œ ì…ë‹ˆë‹¤.
ìŠ¤ì¹¼ë¼ëŠ” ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ê°™ì€ í˜•ìƒìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë©ë‹ˆë‹¤.


```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```

í¬ê¸°ê°€1ì¸ ì¶•ì€ ë‹¤ë¥¸ ì¸ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‘ ì¸ìˆ˜ ëª¨ë‘ ê°™ì€ ê³„ì‚°ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.
3*1ì˜ í–‰ë ¬ì— ìš”ì†Œë³„ë¡œ 1*4 í–‰ë ¬ì„ ê³±í•˜ì—¬ 3*4 í–‰ë ¬ì„ ìƒì„±í•©ë‹ˆë‹¤. ì„ í–‰1ì´ ì„ íƒì‚¬í•­ì¸ ê²ƒì— ìœ ì˜í•˜ì—¬ì•„í•©ë‹ˆë‹¤. yì˜ í˜•ìƒì€ [4]ì…ë‹ˆë‹¤.


```python
# These are the same computations
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))
```

<table>
<tr>
  <th>A broadcasted add: a <code>[3, 1]</code> times a <code>[1, 4]</code> gives a <code>[3,4]</code> </th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/broadcasting.png?raw=1" alt="Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix">
  </td>
</tr>
</table>


ë¸Œë¡œë“œìºìŠ¤íŒ…ì´ ì—†ëŠ” ì—°ì‚°ì…ë‹ˆë‹¤.


```python
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # Again, operator overloading
```

ëŒ€ë¶€ë¶„ ë¸Œë¡œë“œìºìŠ¤íŒ…ì€ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì—°ì‚°ìœ¼ë¡œ ë©”ëª¨ë¦¬ì—ì„œ í™•ì¥ëœ í…ì„œë¥¼ êµ¬ì²´í™”í•˜ì§€ ì•Šì•„ì„œ ì‹œê°„ê³¼ ê³µê°„ì— íš¨ìœ¨ì ì…ë‹ˆë‹¤.
tf.broadcast_toë¥¼ ì´ìš©í•˜ì—¬ ë¸Œë¡œë“œ ìºìŠ¤íŒ…ì´ ì–´ë–¤ ëª¨ìŠµì¸ì§€ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.


```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

ì˜ˆì‹œë¡œ, broadcast_toëŠ” ìˆ˜í•™ì ì¸ opì™€ ë‹¤ë¥´ê²Œ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ íŠ¹ë³„í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ í…ì„œë¥¼ êµ¬ì²´í™”í•©ë‹ˆë‹¤.

í›¨ì”¬ ë³µì¡í•´ ì¤„ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

## tf.convert_to_tensor

tf.matmul , tf.reshapeì™€ ê°™ì€ ëŒ€ë¶€ë¶„ì˜ opsëŠ” í´ë˜ìŠ¤ tf.Tensorì˜ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ê²½ìš° í…ì„œ í˜•ìƒì˜ íŒŒì´ì¬ ê°ì²´ê°€ ìˆ˜ìš©ë˜ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ëŒ€ë¶€ë¶„ì˜ opsëŠ” í…ì„œê°€ ì•„ë‹Œ ì¸ìˆ˜ì— ëŒ€í•´ conver_to_tensor ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ë³€í™˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ê°€ ìˆì–´ì„œ Numpyì˜ ndarray, TensorShape, íŒŒì´ì¬ ëª©ë¡ ë° tf.Variableê³¼ 
ê°™ì€ ëŒ€ë¶€ë¶„ì˜ ê°ì²´ í´ë˜ìŠ¤ëŠ” ëª¨ë‘ ìë™ë³€í™˜ë©ë‹ˆë‹¤.

## ë¹„ì •í˜• í…ì„œ

ì–´ë–¤ ì¶•ì„ ë”°ë¼ ë‹¤ì–‘í•œ ìˆ˜ì˜ ìš”ì†Œë¥¼ ê°€ì§„ í…ì„œë¥¼ "ë¹„ì •í˜• í…ì„œ"ë¼ê³  í•©ë‹ˆë‹¤. ë¹„ì •í˜• ë°ì´í„°ì—ëŠ” tf.ragged.RaggedTensorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ë¹„ì •í˜• í…ì„œëŠ” ì •ê·œ í…ì„œë¡œ í‘œí˜„ ë¶ˆê°€ í•©ë‹ˆë‹¤.

<table>
<tr>
  <th>A `tf.RaggedTensor`, shape: <code>[4, None]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/ragged.png?raw=1" alt="A 2-axis ragged tensor, each row can have a different length.">
  </td>
</tr>
</table>


```python
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]
```


```python
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

tf.ragged.constantë¥¼ ì‚¬ìš©í•˜ì—¬ tf.RaggedTensorë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.


```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```

tf.RaggedTensorì˜ í˜•ìƒì—ëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ê¸¸ì´ì˜ ì¼ë¶€ ì¶•ì´ í¬í•¨ë©ë‹ˆë‹¤.


```python
print(ragged_tensor.shape)
```

## ë¬¸ìì—´ í…ì„œ

tf.stringì€ dtypeì´ë©° í…ì„œì—ì„œ ë¬¸ìì—´ê³¼ ê°™ì€ ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë¬¸ìì—´ì€ ì›ìì„±ì´ë¯€ë¡œ íŒŒì´ì¬ ë¬¸ìì—´ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì¸ë±ì‹±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ë¬¸ìì—´ì˜ ê¸¸ì´ëŠ” í…ì„œ ì¶•ì˜ ì¼ë¶€ê°€ ì•„ë‹™ë‹ˆë‹¤.

ë°‘ì€ ìŠ¤ì¹¼ë¼ ë¬¸ìì—´ í…ì„œì…ë‹ˆë‹¤.


```python
# Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```

ë¬¸ìì—´ì˜ ë²¡í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

<table>
<tr>
  <th>A vector of strings, shape: <code>[3,]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/strings.png?raw=1" alt="The string length is not one of the tensor's axes.">
  </td>
</tr>
</table>


```python
# If you have three string tensors of different lengths, this is OK.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# Note that the shape is (3,). The string length is not included.
print(tensor_of_strings)
```

ìœ„ì˜ ì¶œë ¥ì—ì„œ b ì ‘ë‘ì‚¬ëŠ” tf.string dtypeì´ ìœ ë‹ˆì½”ë“œ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼ ë°”ì´íŠ¸ ë¬¸ìì—´ì¸ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ìœ ë‹ˆì½”ë“œ ë¬¸ìë¥¼ ì „ë‹¬í•˜ë©´ UTF-8ìœ¼ë¡œ ì¸ì½”ë”© ë©ë‹ˆë‹¤.


```python
tf.constant("ğŸ¥³ğŸ‘")
```

ë¬¸ìì—´ì´ ìˆëŠ” ê¸°ë³¸ í•¨ìˆ˜ëŠ” tf.stringsì„ í¬í•¨í•˜ì—¬ tf.strings.splitì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# You can use split to split a string into a set of tensors
print(tf.strings.split(scalar_string_tensor, sep=" "))
```


```python
# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,
# as each string might be split into a different number of parts.
print(tf.strings.split(tensor_of_strings))
```

<table>
<tr>
  <th>Three strings split, shape: <code>[3, None]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/string-split.png?raw=1" alt="Splitting multiple strings returns a tf.RaggedTensor">
  </td>
</tr>
</table>

And `tf.string.to_number`:


```python
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))
```

tf.castë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ í…ì„œë¥¼ ìˆ«ì ë³€í™˜ì€ í•  ìˆ˜ ì—†ì§€ë§Œ, ë°”ì´íŠ¸ë¡œ ë³€í™˜í•œ ë‹¤ìŒ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•©ë‹ˆë‹¤.


```python
byte_strings = tf.strings.bytes_split(tf.constant("Duck"))
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8)
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)
```


```python
# Or split it up as unicode and then decode it
unicode_bytes = tf.constant("ã‚¢ãƒ’ãƒ« ğŸ¦†")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)
```

## í¬ì†Œ í…ì„œ

ë§¤ìš° ë„“ì€ ì„ë² ë“œ ê³µê°„ê³¼ ê°™ì´ ë°ì´í„°ê°€ í¬ì†Œí•©ë‹ˆë‹¤. í…ì„œí”Œë¡œìš°ëŠ” tf.sparse.SparseTensor ë° ê´€ë ¨ ì—°ì‚°ì„ ì§€ì›í•˜ì—¬ í¬ì†Œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

<table>
<tr>
  <th>A `tf.SparseTensor`, shape: <code>[3, 4]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/sparse.png?raw=1" alt="An 3x4 grid, with values in only two of the cells.">
  </td>
</tr>
</table>


```python
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# You can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))
```
