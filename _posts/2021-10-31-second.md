---
layout: single
title:  "머신러닝 작업흐름 일반에 대한 과제입니다."
---

# 머신 러닝의 보편적인 워크플로우
 
  시작할 레이블이 지정된 데이터 세트가 이미 있고, 모델 교육을 즉시 시작할 수 있다고 가정했습니다. 
  현실에서는 그렇지 않은 경우가 많습니다. 데이터 세트에서 시작하는 것이 아니라 문제에서 시작하는 것입니다.
  
  자신의 기계 학습 컨설팅 상점을 시작한다고 상상해보세요. 멋진 웹사이트를 만들고 네트워크에 알리게 됩니다.
  ○ 사진 공유소셜네트워크 사용자를 위한 개인화된 사진 검색 엔진 "웨딩"을 입력하면 수동태깅 없이 결혼식에서
  찍은 모든 사진을 검색할수 있습니다.
  ○ 신진 채팅 앱의 게시물 중 스팸 및 불쾌감을 주는 텍스트 콘텐츠를 신고합니다.
  ○ 온라인 라디오 사용자를 위한 음악 추천 시스템 구축
  ○ 전자상 거래 웹사이트에 대한 신용카드 사기 탐지
  ○ 디스플레이 광고 클릭률을 예측하여 주어진 시간에 특정 사용자에게 어떤 광고를 게재할지 결정합니다.
  ○ 쿠키 제조 라인의 컨베이어 벨트에서 변칙 쿠키에 플래그를 지정합니다. 
  ○ 위성 이미지를 사용하여 아직 알려지지 않은 고고학 유적지의 위치를 예측합니다.
  
  # 윤리상의 주의. 

  

당신은 때때로 "사람의 얼굴 사진으로 신뢰도를 평가하는 AI를 구축하라"와 같은 윤리적으로 의심스러운 프로젝트를 제안받을 수 있다. 먼저, 프로젝트의 타당성은 의심스럽다: 왜 신뢰성이 누군가의 얼굴에 반영되는지는 명확하지 않다. 둘째, 그러한 일은 모든 종류의 윤리적 문제에 대한 문을 연다. 이 작업에 대한 데이터 세트를 수집하는 것은 사진을 좋아하는 사람들의 편견과 편견을 기록하는 것과 같다. 이러한 데이터에 대해 훈련하는 모델은 단순히 이러한 동일한 편견을 블랙박스 알고리즘으로 인코딩하여 적법성의 얇은 허울을 제공하는 것일 뿐입니다. 우리와 같은 대체로 기술 문맹인 사회에서, "AI 알고리즘은 이 사람을 신뢰할 수 없다고 말했다"는 전자가 후자의 학습된 근사치임에도 불구하고 "존 스미스가 이 사람을 신뢰할 수 없다고 말했다"보다 이상하게도 더 비중과 객관성을 가지고 있는 것으로 보인다. 당신의 모델은 실제 사람들의 삶에 부정적인 영향을 미치면서 인간의 판단의 가장 나쁜 측면들을 세탁하고 운영할 것이다.기술은 결코 중립일 수 없다. 만약 당신의 작품이 세상에 영향을 미친다면, 이 영향은 도덕적인 방향을 가지고 있다: 기술적인 선택 또한 윤리적 선택이다. 당신의 작품이 뒷받침하기를 바라는 가치에 대해 항상 숙고하세요 

keras.datasets 에서 올바른 데이터 세트를 가져와 일부 딥 러닝 모델을 적합시킬 수 있다면 매우 편리할 것입니다. 불행히도 현실 세계에서는 처음부터 다시 시작해야 할 것이다. 

이 장에서는 위에 나열된 문제와 같은 머신 러닝 문제에 접근하고 해결하는 데 사용할 수 있는 범용 setp-by-step Blueprint에 대해 알아봅니다.이 템플릿은 4장과 5장에서 배운 모든 내용을 통합하고 통합하며, 다음 장에서 배울 내용을 파악할 수 있는 더 강력한 컨텍스트를 제공합니다. 

머신 러닝의 보편적인 작업 흐름은 크게 세 부분으로 구성된다. 

○작업을 정의합니다. 고객이 요청한 사항의 기반이 되는 문제 영역과 비즈니스 논리를 이해하고, 데이터 세트를 수집하고, 데이터가 나타내는 바를 이해하고, 작업의 성공을 측정하는 방법을 선택합니다. 

○모델 개발: 머신러닝 모델에서 데이터를 처리할 수 있도록 준비, 모델 이탈 프로토콜 및 간단한 기준선을 선택하고, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다. 

○모델 배포: 이해 관계자에게 작업물을 전달하고, 웹 서버, 모블리 앱, 웹 페이지 또는 임베디드 장치로 모델을 전달하며, 야생에서의 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집하기 시작합니다. 

 

 

 

# 과업을 정의하다 

 자신이 하는 일의 맥락을 깊이 이해하지 않고는 좋은 일을 할 수 없다. 왜 당신의 고객은 이 특정한 문제를 해결하려고 하는가? 고객이 솔루션에서 어떤 가치를 창출할 수 있을까요? 모델이 어떻게 사용될 것이며 고객의 비즈니스 프로세스에 어떻게 부합될까요? 어떤 종류의 데이터를 이용할 수 있거나 수집할 수 있는가? 어떤 종류의 기계 학습 과제가 비즈니스 문제에 매핑될 수 있는가? 
 
# 문제를 조작하다 

기계 학습 문제의 틀은 일반적으로 이해관계자들과의 많은 상세한 논의를 수반한다. 여기 여러분의 마음 위에 있어야 할 질문들이 있습니다. 

○당신의 입력 데이터는 무엇이 될 것인가? 당신은 무엇을 예측하려고 하는가? 예를 들어 영화 리뷰와 감정 주석이 모두 있는 경우에만 영화 리뷰의 감정을 분류하는 방법을 배울 수 있습니다. 이와 같이, 이 단계에서 데이터 가용성은 보통 제한 요소이다. 많은 경우, 직접 새 데이터 세트를 수집하고 주석을 달아야 합니다(다음 섹션에서 다루겠습니다). 

○당신은 어떤 종류의 기계 학습 과제를 직면하고 있습니까? 이진 분류인가요? 다중 클래스 분류인가요, 다중 라벨 분류인가요? 영상 분할? 순위요? 클러스터링, 생성, 강화 학습과 같은 다른 것이 있습니까? 어떤 경우에는 머신러닝이 데이터를 이해하는 가장 좋은 방법이 아닐 수도 있으며, 당신은 평범한 구식 통계 분석과 같은 다른 것을 사용해야 한다. 

 - 사진 검색 엔진 프로젝트는 다중 클래스, 다중 레이블 분류 작업입니다. 

 - 스팸 탐지 프로젝트는 이진 분류 태스크입니다. 콘텐츠를 별도의 클래스로 설정하면 3방향 분류 작업이 됩니다. 

 - 음악 추천 엔진은 딥 러닝이 아닌 매트릭스 인수분해(추측 필터링)를 통해 더 잘 처리되는 것으로 밝혀졌다. 

 - 신용카드 사기 탐지 프로젝트는 이진 분류 작업입니다. 

 - 클릭률 예측 프로젝트는 스칼라 회귀 작업이다. 

 - 변칙적인 쿠키 탐지는 이진 분류 작업이지만 원시 이미지에서 쿠키를 올바르게 잘라내기 위해서는 첫 번째 단계로서 객체 탐지 모델이 필요하다. 이 설정에는 "감지 감지"로 알려진 기계 학습 기술 세트가 적합하지 않습니다! 

 - 위성사진에서 새로운 고고학 유적지를 찾는 프로젝트는 이미지 유사성 순위 매기기 과제이다. 알려진 고고학 유적지와 가장 유사한 새로운 이미지를 검색해야 한다. 

○기존 솔루션은 어떤 모습입니까?아마도 당신의 고객은 이미 스팸 필터링이나 신용카드 사기 탐지를 처리할 수 있는 수작업 알고리즘을 가지고 있을 것이다. 아마도 한 사람이 현재 쿠키 공장에서 컨베이어 벨트를 감시하고 나쁜 쿠키를 수동으로 제거하거나 특정 아티스트를 좋아하는 사용자에게 보낼 노래 추천 재생 목록을 만드는 과정을 수동으로 담당하고 있을 것이다. 어떤 시스템이 이미 구축되어 있고 어떻게 작동하는지 확실히 이해해야 합니다. 

○처리해야 할 특별한 제약이 있습니까? 그래서 스팸 탐지 모델 최종 사용자의 전화에 살고 있으며 외부의 데이터에 훈련되어야 합니다 할 것이다 예를 들어,에게 당신이 스팸 탐지 시스템을 만들고 있습니다 앱은 정확하게 끝 암호화된 끝내기 위해 찾을 수 있어 아마도 쿠키 필터링 모델은 원격 서버보다는 공장에서 임베디드 장치에서 실행되어야 하는 지연 시간 제약 조건을 가지고 있을 것이다. 당신은 당신의 작품이 들어맞을 전체 맥락을 이해해야 한다. 

 

일단 당신이 조사를 한 후에는, 당신은 당신의 입력이 무엇일지, 당신의 목표가 무엇인지, 그리고 문제가 어떤 종류의 기계 학습 과제로 매핑되는지 알아야 한다. 이 단계에서 여러분이 하는 가설에 유의하십시오. 

○입력이 주어지면 목표값을 예측할 수 있다는 가설을 세웁니다. 

○사용 가능한 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다. 

 

이는 검증되거나 무효화되기를 기다리는 가설에 불과합니다. 모든 문제가 기계 학습으로 해결될 수 있는 것은 아니다; 단지 당신이 입력 x와 목표 y의 예들을 제거했다고 해서 x가 y를 예측하기에 충분한 정보를 포함하고 있다는 것을 의미하지 않는다. 예를 들어, 만약 당신이 그것의 최근 가격 이력을 감안하여 주식 시장에서 주식의 움직임을 예측하려고 한다면, 당신은 성공할 것 같지 않다. 왜냐하면 가격 이력 때문이다.예측 정보가 많이 포함되어 있지 않습니다. 

 

# 데이터 세트를 수집하다 

 작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분을 데이터 수집해야 합니다. 

 ○사진 검색 엔진 프로젝트는 먼저 10000개의 일반적인 이미지 범주에 대해 분류하려는 라벨 세트를 선택해야 합니다. 그런 다음 이 세트의 레이블로 과거 사용자가 업로드한 이미지 수십만 개에 수동으로 태그를 지정해야 합니다. 

 ○채팅 앱 스팸 탐지 프로젝트에서는 사용자 채팅이 종단 간 암호화되기 때문에 해당 콘텐츠를 사용하여 수만 개의 공개 소셜 미디어 게시물의 개별 데이터 세트에 액세스할 수 없으며 수동으로 스팸, 불쾌감 또는 허용 가능한 태그를 지정할 수 없습니다. 

 ○쿠키 플래깅 모델의 경우, 당신은 수만개의 이미지를 수집하기 위해 컨베이어 벨트 위에 카메라를 설치해야 할 것이고, 그리고 나서 누군가가 수동으로 이 이미지들에 라벨을 붙여야 할 필요가 있다. 이것을 할 줄 아는 사람들은 현재 쿠키 공장에서 일하고 있지만 그렇게 어렵지 않아 보인다, 당신은 그것을 할 수 있는 사람들을 훈련시킬 수 있어야 한다. 

○위성사진 프로젝트는 고고학자들로 구성된 팀이 관심 장소의 데이터베이스를 수집해야 할 것이며, 각 사이트에 대해 다른 날씨 조건에서 촬영된 기존 위성 사진을 찾아야 할 것이다. 좋은 모델을 얻으려면 수천 개의 다른 사이트가 필요할 것입니다. 

  

알고리즘보다 데이터가 더 중요하다는 지적은 구글 연구원들이 2009년 발표한 '데이터의 불합리한 효과'(유진 위그너의 1960년 저서 '자연과학에서의 수학의 불합리한 효과'에 대한 리프)에서 가장 유명하다. 이것은 딥러닝이 대중화되기 전이었지만, 놀랍게도 딥러닝의 부상은 데이터의 중요성만을 더 크게 만들었다. 

 

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석이 필요합니다. 즉, 모델이 예측하도록 교육할 목표입니다. 

때로는 음악 추천 작업이나 클릭률 예측 작업의 경우 주석이 자동으로 검색될 수 있다. 그러나 종종 데이터에 주석을 직접 달아야 합니다. 이것은 노동력이 많이 드는 과정이다. 

 

# 데이터 정보 인프라에 대한 투자 

 데이터 주석 공정에서 목표물의 품질을 결정하고, 이는 다시 모형의 품질을 결정합니다. 사용할 수 있는 옵션을 신중하게 고려하십시오. 

○데이터에 주석을 직접 달아야 합니까? 

○당신은 라벨을 모으기 위해 메타니컬 터크 같은 크라우드소싱 플랫폼을 사용해야 하는가? 

○당신은 전문적인 데이터 라벨링 회사의 서비스를 이용해야 하는가? 

 

아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제력을 잃게 합니다. 기계식 터크와 같은 것을 사용하는 것은 비싸지 않고 잘 확장될 수 있지만, 당신의 주석들은 꽤 시끄럽게 끝날 수 있다. 

  

최상의 옵션을 선택하려면 다음과 같은 제약 조건을 고려해야 합니다. 

 ○데이터 라벨 작성자가 주제 전문가가 되어야 하는가, 아니면 데이터에 주석을 달 수 있는 사람이 있는가? 고양이 대 개 이미지 분류 문제의 랩은 누구나 선택할 수 있지만 개 품종 분류 작업의 랩은 전문 지식이 필요하다. 뼈 골절의 CT 스캔에 주석을 달려면 의학 학위가 필요 하다. 

○데이터에 주석을 달려면 전문 지식이 필요한데, 이를 위해 사람들을 훈련시킬 수 있는가? 그렇지 않다면 관련 전문가에게 어떻게 접근할 수 있는가? 

○당신은 전문가들이 어떻게 주석을 달 수 있는지 이해하나요? 그렇지 않은 경우 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없게 됩니다. 

 

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하기 위해 어떤 소프트웨어를 사용할지 자문해 보십시오. 당신이 직접 그 소프트웨어를 개발해야 할 수도 있습니다. 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다. 

 

# 비반복적인 자료에 주의하다. 

 머신러닝 모델은 이전에 본 것과 유사한 입력만 이해할 수 있으므로 교육에 사용되는 데이터가 생산 데이터를 대표하는 것이 매우 중요합니다. 모든 데이터 수집 작품의 이 문제의 근본이다. 

 

사용자가 음식 이름을 알기 위해 사진을 찍을 수 있는 앱을 개발 중이라고 가정해 보자. 미식가들에게 인기 있는 이미지 공유 소셜 네트워크의 사진을 사용하여 모델을 교육합니다. 배포 시간이 다가오고, 화난 사용자들의 피드백이 쏟아지기 시작한다: 당신의 앱은 10점 만점에 8번 오답한다. 무슨 일인가? 테스트 세트에 대한 당신의 정확도는 90%를 훨씬 넘었다! 사용자가 업로드한 데이터를 빠르게 살펴보면 랜덤 스마트폰으로 찍은 랜덤 레스토랑의 랜덤 접시의 모바일 사진 업로드가 전혀 같지 않다는 것을 알 수 있다.전문적인 품질, 채광이 잘 되고 식욕을 돋우는 사진: 귀하의 교육 데이터는 생산 데이터를 대표하지 않습니다. 기계학습 지옥에 온 걸 환영한다 

 

가능하면 모델이 사용될 환경에서 직접 데이터를 수집하면 옐프 레스토랑 리뷰나 트위터 상태 업데이트가 아닌 새로운 IMDB 리뷰에 영화 리뷰 감정 분류 모델을 사용해야 한다. 트윗의 감성을 평가하려면 프로덕션에서 예상하는 것과 유사한 사용자 집합에서 실제 트윗을 수집하고 주석을 다는 것부터 시작하십시오. 프로덕션 데이터에 대한 교육을 수행할 수 없다면 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다. 

유의해야 할 관련 현상은 개념 드리프트입니다. 거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념 드리프트가 발생합니다. 컨셉트 드리프트는 시간이 지남에 따라 생산 데이터의 특성이 변화하여 모델 정확도가 점차 저하될 때 발생한다. 2013년에 훈련된 음악 추천 엔진은 오늘날 매우 효과적이지 않을 수 있다. 마찬가지로, 함께 작업한 IMDB 데이터 집합은 2011년에 수집되었으며, 이에 대해 훈련된 모델은 어휘, 표현 및 영화 장르가 시간이 지남에 따라 발전함에 따라 2012년의 리뷰에 비해 2020년의 리뷰에서 잘 수행되지 못할 가능성이 높다. 개념 드리프트는 신용 카드 사기 감지와 같은 적대적인 맥락에서 특히 심각하며, 사기 패턴이 실질적으로 매일 변화한다. 빠른 개념 드리프트를 다루는 것은 지속적인 데이터 수집, 주석 및 모델 재교육을 필요로 한다. 

  

기계 학습은 당신의 훈련 데이터에 존재하는 패턴을 암기하는데만 사용될 수 있다는 것을 명심하세요. 전에 본 것만 알아볼 수 있어요 미래를 예측하기 위해 과거 데이터에 대해 훈련된 기계 학습을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 만드는 것이다. 그것은 종종 사실이 아니다. 

# 참고: 표본 추출 편향 문제 

 특히 교활하고 일반적인 비반복적 데이터의 경우는 샘플링 편향이다. 표본 추출 편향은 데이터 수집 과정이 예측하려는 것과 상호 작용하여 편향된 측정을 초래할 때 발생한다. 유명한 역사적 예는 1948년 미국 대통령 선거에서 일어났다. 선거날 밤 시카고 호민관은 "실제로 트루먼을 꺾다"라는 헤드라인을 실었다. 다음날 아침 트루먼이 승자로 나타났다. Trubune의 편집자는 전화 설문조사의 결과를 신뢰했지만 1948년의 전화 사용자들은 무작위적인 투표자 표본이 아니었다. 그들은 더 부유하고, 보수적이며, 공화당 후보인 듀이에게 투표할 가능성이 높았다. 오늘날, 모든 전화 조사는 표본 추출 편향을 고려합니다. 그러나 1948년과 달리 여론조사기관들은 이를 인식하고 이를 바로잡기 위한 조치를 취하고 있다. 

 

# 데이터를 이해하다 

 데이터 세트를 블랙박스로 취급하는 것은 매우 나쁜 관행입니다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 무엇이 예측하여 기능 엔지니어링 및 스크린에 잠재적인 문제를 알려주는지에 대한 통찰력을 얻어야 합니다. 

 ○데이터에 이미지 또는 자연어 텍스트가 포함되어 있다면 몇 가지 샘플(및 해당 라벨)을 직접 살펴보십시오. 

 ○데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하는 것이 좋습니다. 

 ○데이터에 위치 정보가 포함되어 있다면 지도에 표시하십시오. 뚜렷한 패턴이 있습니까? 

 ○일부 샘플에 일부 형상에 대한 결측값이 있습니까? 그렇다면 데이터를 준비할 때 이 문제를 해결해야 합니다(다음 섹션에서 이 작업을 수행하는 방법에 대해 설명합니다). 

 ○작업이 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 인쇄합니다. 클래스가 대략적으로 동등하게 표현되는가? 그렇지 않다면 이 불균형을 고려해야 합니다. 

 ○목표 누출 여부: 데이터에 생산 시 사용할 수 없는 대상에 대한 정보를 제공하는 티처가 있는지 확인합니다. 만약 당신이 미래에 언제 다른 누군가가 암으로 치료받을지 예측하기 위해 의료기록에 관한 모델을 훈련하고 있고, 기록에는 "이 사람이 암 진단을 받았다"는 특징이 포함되어 있다면, 당신의 목표물은 인위적으로 당신의 데이터에 유출되고 있는 것이다. 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 자문해 보십시오. 

# 성공의 척도를 선택하다 

 무언가를 통제하려면, 당신은 그것을 관찰할 필요가 있고, 프로젝트에서 성공을 이루기 위해, 당신은 먼저 성공 정확성이 무엇을 의미하는지를 정의해야 하는가? 정확성과 기억력? 고객 유지율? 성공을 위한 당신의 측정 기준은 프로젝트 전체에서 당신이 할 모든 기술적 선택을 안내할 것입니다. 고객의 비즈니스 성공과 같은 상위 수준의 목표에 직접적으로 부합해야 합니다. 

  

모든 클래스가 동등하게 발생할 가능성이 있는 균형 분류 문제의 경우, 수신기 작동 특성 곡선 하의 정확도와 영역이 일반적인 지표이다. 클래스 문제, 순위 문제 또는 다중 분류의 경우 정확도 및 호출뿐만 아니라 가중치 형태의 정확도 또는 ROC AUC를 사용할 수 있으며 성공을 측정하기 위해 자신만의 사용자 지정 메트릭을 정의해야 하는 것은 문제가 아닙니다. 머신러닝 성공 지표의 다양성과 그것들이 서로 다른 문제 영역과 어떻게 관련되는지 알기 위해서는, 광범위한 문제와 평가 지표를 보여주는 Kaggle의 데이터 과학 대회를 살펴보는 것이 도움이 된다. 

 

# 자료를 준비하다 

 앞에서 배웠듯이, 딥러닝 모델은 일반적으로 원시 데이터를 섭취하지 않습니다. 데이터 전처리는 당면한 원시 데이터를 신경망에 더 잘 적응시키는 것을 목표로 합니다. 여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다. 많은 사전 처리 기법은 도메인마다 다르다(예: 텍스트 데이터 또는 이미지 데이터에 한정됨). 실제 예제에서 접하게 될 때 다음 장에서 다룰 것이다. 지금은 모든 데이터 도메인에 공통적으로 적용되는 기본 사항에 대해 살펴보겠습니다.  

# 벡터화 

 신경망의 모든 입력과 대상은 부동소수점 데이터의 튜핑 텐서(또는 특정한 경우, 인터거 또는 문자열의 텐서)여야 한다. 소리, 이미지, 텍스트를 처리하기 위해 필요한 데이터가 무엇이든 먼저 텐서로 변환해야 합니다. 이는 데이터 벡터화라고 합니다. 예를 들어, 4장의 이전 두 텍스트 분류 예에서는 정수 목록으로 표현된 텍스트에서 시작하여 하나의 핫 인코딩을 사용하여 float32 데이터의 텐서로 변환했다. 숫자를 분류하고 집값을 예측하는 예에서는 데이터가 이미 벡터화된 형태로 제공되기 때문에 이 단계를 건너뛸 수 있습니다. 

# 가치 정상화 

 2장의 MNIST 숫자 분류 예에서, 당신은 0-255 범위의 정수로 인코딩된 이미지 데이터에서 시작했다. 이 데이터를 당신의 네트워크에 공급하기 전에 당신은 그것을 부동 소수점 값으로 0-1 범위의 부동 소수점 값으로 만들기 위해 32로 나누고 255로 나누어야 했다. 마찬가지로 주택 가격을 예측할 때, 당신은 부동 소수점 값이 작고 정수 값이 상당히 큰 다양한 범위의 반복으로부터 시작했다. 이 데이터를 네트워크에 공급하기 전에, 당신은 표준 편차가 1이고 평균이 0이 되도록 각각의 특징을 독립적으로 정규화해야 했다. 

 

일반적으로, 상대적으로 큰 값이나 이종 데이터를 사용하는 신경망 데이터에 입력하는 것은 안전하지 않습니다. 그렇게 하는 것은 네트워크가 수렴되지 않도록 하는 큰 경사도 업데이트를 트리거할 수 있습니다. 네트워크를 더 쉽게 학습하기 위해 데이터는 다음과 같은 특성을 가져야 합니다. 

 ○일반적으로 작은 값을 사용합니다. 대부분의 값은 0-1 범위여야 합니다. 

 ○즉, 모든 형상이 거의 동일한 범위의 값을 가져야 한다. 

 

추가적으로, 항상 필요한 것은 아니지만, 다음과 같은 엄격한 정규화 실천이 일반적이고 도움이 될 수 있다. 또한 다음과 같은 엄격한 정규화 관행이 일반적이며 도움이 될 수 있지만 항상 필요한 것은 아닙니다. 

 ○평균이 0이 되도록 각 피쳐를 독립적으로 정규화 

 ○표준 편차가 1이 되도록 각 피쳐를 독립적으로 정규화 

 

# 결측값 처리 

  때때로 데이터에 결측값이 있을 수 있습니다. 예를 들어, 집값의 예에서, 첫 번째 특징은 1인당 범죄율이다. 모든 샘플에 이 기능을 사용할 수 없다면 어떨까요? 그러면 교육 또는 검정 데이터에 결측값이 있게 됩니다. 

이 기능을 완전히 폐기할 수 있지만, 반드시 다음과 같은 작업을 수행할 필요는 없습니다. 

 ○피쳐가 범주형인 경우 "값이 누락됨"을 의미하는 새 범주를 작성하는 것이 안전합니다. 모델은 목표와 관련하여 이것이 내포하는 의미를 자동으로 학습할 것이다. 

 ○만약 형상이 수치적이라면, 형상에 의해 형성된 잠재 공간에 불연속성을 만들 수 있기 때문에 "0"과 같은 임의의 값을 입력하는 것을 피하라. 대신 결측값을 데이터 집합의 기능에 대한 평균값 또는 중위값으로 바꾸는 것을 고려하십시오. 다른 형상의 값이 주어진 형상의 값을 예측하도록 모형을 교육할 수도 있습니다. 

  

테스트 데이터에서 누락된 범주형 피쳐가 예상되지만 네트워크에서 결측값을 무시하는 방법을 배우지 않을 경우, 누락된 엔트리가 있는 교육용 샘플을 인위적으로 생성하고 일부 교육용 샘플을 여러 번 복사하고 잘못되었을 것으로 예상되는 범주형 피쳐 중 일부를 삭제해야 합니다. 

 

# 평가 프로토콜을 선택하다 

 이전 장에서 학습한 바와 같이 모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내리는 모든 모델링 결정은 일반화 성능을 측정하기 위한 검증 메트릭스에 의해 안내됩니다. 검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 메트릭을 정확하게 추정하는 것입니다. 이 공정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다. 

○홀드 아웃 유효성 검사를 유지하는 것은 데이터가 많을 때 가능한 방법입니다. 

○검체가 너무 적어서 검증이 신뢰할 수 없을 때 k-fold 교차 검증을 수행하는 것이 올바른 선택임 

○ 데이터가 거의 없을 때 매우 정확한 모델 평가를 수행하기 위해 k-폴드 반복 검증 수행 

이것들 중 하나만 골라요. 대부분의 경우 첫 번째는 충분히 효과가 있을 것이다. 앞에서 학습한 바와 같이, 항상 검증 세트의 대표성에 유의하고, 교육 세트 사이에 중복 샘플이 발생하지 않도록 주의하십시오. 

 # 기준선을 뛰어넘다 

  모델 자체에 대한 작업을 시작하면 5장에서 살펴본 것처럼 통계적 검정력을 달성하는 것이 초기 목표입니다. 즉, 간단한 기준선을 능가할 수 있는 작은 모형을 개발하는 것입니다. 

  

이 단계에서 가장 중요한 세 가지 사항은 다음과 같습니다. 

○ 기능 엔지니어링은 유용한 기능이 없는 기능을 걸러내고 문제에 대한 지식을 활용하여 유용할 수 있는 새로운 기능을 개발합니다. 

○정확한 아키텍처 이전: 조밀하게 연결된 네트워크, 컨브넷, 순환 신경망, 변압기 중 어떤 유형의 모델 아키텍처를 사용할 것인가? 딥러닝은 과제를 위한 좋은 접근법인가요, 아니면 다른 것을 사용해야 하나요? 

○ 충분한 교육 구성을 선택하고 어떤 손실 기능을 사용해야 합니까? 배치 크기와 학습률은 어떻게 됩니까? 

# 참고:올바른 손실 함수를 표시합니다. 

문제의 성공을 측정하는 메트릭에 대해 직접 최적화하지 못하는 경우가 많습니다. 때때로 메트릭을 손실 함수로 바꾸는 쉬운 방법이 없다; 결국 손실 함수는 데이터의 작은 부분만 주어진다면 계산 가능해야 하고 미분이어야 한다. 예를 들어, 널리 사용되는 분류 ROC AUC는 직접 최적화될 수 없습니다.따라서 분류 작업에서 교차 엔트로피와 같은 ROC AUC의 프록시 메트릭에 최적화하는 것이 일반적이다. 일반적으로 교차 엔트로피가 낮을수록 ROC AUC가 더 높아지기를 바랄 수 있습니다. 

대부분의 문제에서 시작할 수 있는 기존 템플릿이 있습니다. 스팸 탐지기, 음악 추천 엔진 또는 이미지 분류기를 만든 첫 번째 사람은 아닙니다. 여러분의 취향에 가장 잘 맞는 기능 엔지니어링 기술과 모델 아키텍처를 식별하기 위해 선행 기술을 조사해야 합니다. 

  

통계적 힘을 얻는 것이 항상 가능한 것은 아닙니다. 합리적인 여러 아키텍처를 시도하고도 단순한 기준선을 넘을 수 없는 경우, 여러분이 묻는 질문에 대한 답이 입력 데이터에 없을 수 있습니다. 

○ 입력이 주어지면 출력을 예측할 수 있다는 가설을 세웁니다. 

○ 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다. 

이러한 가설은 거짓일 수 있으며, 이 경우 처음부터 다시 시작해야 합니다. 

# 스케일업: 지나치게 적합한 모델 개발 

  

통계적 능력을 갖춘 모델을 얻으면 문제는 모델이 충분히 강력한가? 문제를 적절하게 모델링하기에 충분한 계층과 매개 변수를 가지고 있는가 하는 것입니다. 예를 들어, 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이이며 이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델이라는 점을 기억하십시오. 이 국경이 어디에 있는지 알아내려면, 먼저 그 국경을 넘어야 한다 

  

얼마나 큰 모델이 필요한지 파악하려면 지나치게 적합한 모델을 개발해야 합니다. 5장에서 학습한 바와 같이 매우 쉽습니다. 

1. 레이어를 추가합니다. 

2. 층을 크게 만든다. 

3. 더 많은 훈련하라. 

  

교육 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 교육 및 검증 값도 항상 모니터링합니다. 검증 데이터에 대한 모형의 성능이 저하되기 시작하면 과적합이 이루어진 것입니다. 

 

# 모델을 정규화하고 조정합니다. 

  

일단 통계적 능력을 달성하고 오버핏을 할 수 있게 되면, 여러분은 올바른 길을 가고 있다는 것을 알게 됩니다. 이 시점에서 여러분의 목표는 일반화 성능을 극대화하는 것입니다. 

  

이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고, 교육하고, 검증 데이터를 평가하고, 다시 수정하고, 반복합니다. 다음은 시도해 보아야 할 몇 가지 사항입니다. 

○다양한 아키텍처 시도, 레이어 추가 또는 제거 

○탈퇴자 추가 

○모형이 작은 경우 L1 또는 L2 정규화를 추가합니다. 

○다양한 하이퍼 파라미터를 사용해 최적의 구성을 찾습니다. 

○선택적으로 데이터 큐레이션 또는 기능 엔지니어링을 반복할 수 있습니다. 더 많은 데이터를 수집 및 주석 달기, 더 나은 기능 개발 또는 유익한 것으로 보이지 않는 기능 제거 

  

Keras와 같은 자동화된 하이퍼 파라미터 튜닝 소프트웨어를 사용하여 이 작업의 상당 부분을 자동화할 수 있습니다.튜너. 13장에서 다루도록 하겠습니다. 

  

검증 프로세스의 피드백을 모델에 사용할 때마다 다음 사항에 유의하십시오. 몇 번만 반복해도 무해하지만 여러 번 반복하면 결국 모델이 검증 프로세스에 과도하게 적합될 수 있습니다. 이것은 평가 과정의 신뢰성을 떨어뜨린다. 

  

일단 당신이 만족스러운 모델 구성을 개발하면, 당신은 사용 가능한 모든 데이터에 대한 당신의 최종 생산 모델을 훈련시키고 그것을 테스트 세트에서 마지막으로 평가할 수 있다. 만약 테스트 테스트 테스트의 성능이 검증 데이터에서 측정된 성능보다 현저하게 더 나쁜 것으로 판명되면, 이것은 당신의 검증 절차를 의미할 수 있다. 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했기 때문입니다. 이 경우 신뢰할 수 있는 평가 프로토콜로 전환할 수 있습니다. 

# 모델 구축 

모델이 배포 및 생산적인 수명 동안 테스트 세트에 대한 최종 평가를 성공적으로 마쳤습니다. 

# 이해 관계자에게 작업을 설명하고 기대치를 설정 

  

성공과 고객 신뢰는 지속적으로 사람들의 기대를 충족시키거나 초과하는 것입니다. 실제로 제공하는 시스템은 출시 전에 적절한 기대치를 설정하는 그림의 절반에 불과합니다. 

  

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적이다. 예를 들어, 그들은 시스템이 과제를 "이해"하고 과제 맥락에서 상식처럼 인간을 행사할 수 있다고 기대할 수 있다. 이 문제를 해결하려면 모형의 고장 모드의 몇 가지 예를 보여 주는 것을 고려해야 합니다. 

  

그들은 또한 특히 이전에 사람이 처리했던 프로세스에 대해 인간 수준의 성능을 기대할 수 있다. 대부분의 기계 학습 모델은 인간이 생성한 라벨에 근접하도록 훈련되기 때문에 거의 달성하지 못한다. 모형 성능 기대치를 명확하게 전달해야 합니다. "모델은 98%의 정확도를 가지고 있다"와 같은 추상적인 문장을 사용하는 것을 피하고 대화를 선호합니다. 예를 들어, 거짓 음성 비율과 거짓 양성 비율에 대한 것입니다. "이러한 설정에서 부정 행위 탐지 모델은 5퍼센트의 거짓 음성 비율과 2.5%의 거짓 양성률을 갖게 됩니다. 매일 평균 200개의 유효한 트랜잭션이 사기 및 수동 검토를 위해 스넷으로 플래그가 지정되고 평균 14개의 부정 트랜잭션이 누락됩니다. 평균 266건의 부정거래가 정확하게 적발될 수 있습니다."라고 명시되어 있으며, 는 모델의 성능 메트릭스를 비즈니스 목표와 명확하게 연관시킵니다.  

  

또한 주요 시작 매개 변수(예: 트랜잭션에 플래그를 지정해야 하는 확률 임계값)의 선택에 대해 이해 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 맥락을 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다. 

# 추론 모델 전달 

  

기계 학습 프로젝트는 훈련된 모델을 저장할 수 있는 콜랩 노트북에 도착했다고 해서 끝나지 않습니다. 훈련 중에 조작한 것과 동일한 파이썬 모델 객체를 프로덕션으로 넣는 일은 거의 없습니다. 

먼저 모델을 파이썬이 아닌 다른 것으로 내보낼 수 있습니다. 

○ 운영 환경은 예를 들어 모블리 앱이나 임베디드 시스템일 경우 파이썬을 전혀 지원하지 않을 수 있습니다. 

○나머지 앱이 python으로 되어 있지 않다면, 모델을 서비스하기 위해 python을 사용하면 상당한 오버헤드가 발생할 수 있습니다. 

  

둘째, 프로덕션 모델은 교육용이 아니라 사전 조건을 출력하는 데만 사용되므로 모델을 더 빠르게 만들고 메모리 설치 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다. 

  

이제 사용 가능한 다양한 모델 배포 옵션을 간단히 살펴보겠습니다. 

# REST API로 모델 구축 

모델을 제품으로 변환하는 일반적인 방법은 다음과 같습니다.  

서버나 클라우드 인스턴스에 텐서플로를 설치하고 REST API를 통해 모델의 예측을 쿼리합니다. 플라스크와 같은 것을 사용하여 자신만의 서빙 앱을 구축하거나 텐서플로우 자체 라이브러리를 사용하여 모델을 API로 제공할 수 있습니다. 텐서플로우 서빙을 사용하여 케라스 모델을 몇 분 안에 배포할 수 있습니다. 

  

다음과 같은 경우 이 배포 설정을 사용해야 합니다. 

○모델의 예측을 소비할 애플리케이션은 인터넷에 안정적으로 액세스할 수 있을 것입니다. 예를 들어, aplication이 모바일 앱인 경우 원격 API에서 예측을 제공한다는 것은 비행기 모드나 낮은 연결 환경에서 애플리케이션을 사용할 수 없음을 의미합니다. 

○응용 프로그램에는 엄격한 대기 시간 요구사항이 없습니다. 요청, 추론 및 응답 왕복에는 일반적으로 약 500ms가 소요됩니다. 

○추론을 위해 전송된 입력 데이터는 그다지 민감하지 않습니다. 데이터는 모델에 의해 보여져야 하므로 해독된 형태로 서버에서 사용할 수 있어야 합니다. 

  

예를 들어 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용카드 사기 탐지 프로젝트, 위성 이미지 프로젝트는 모두 REST API를 통해 서비스를 제공하기에 적합합니다. 

  

REST AIP로 모델을 배포할 때 중요한 질문은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부입니다. 예를 들어 구글 제품인 클라우드 AI 플랫폼을 사용하면 텐서플로우 모델을 구글 클라우드 스토리지에 업로드하고 API 끝점을 제공해 쿼리할 수 있다. 일괄 처리 사전 설정, 부하 분산 및 스케일링과 같은 많은 실제적인 세부 사항을 처리합니다. 

# 장치에 모델 배치 

때때로, 당신은 그것을 사용하는 응용 프로그램을 실행하는 같은 장치에 살고, 로봇에 내장된 ARM CPU, 또는 티미 장치에 마이크로컨트롤러를 사용하기 위해 당신의 모델이 필요할지도 모른다. 예를 들어, 아마 여러분은 이미 카메라에서 직접 동작하는 작은 딥러닝 모델인, 여러분이 가리키는 장면에서 사람과 얼굴을 압도적으로 감지할 수 있는 카메라를 본 적이 있을 것이다. 

  

다음과 같은 경우 이 설정을 사용해야 합니다. 

○ 모델은 지연 시간이 엄격하거나 연결성이 낮은 환경에서 실행되어야 합니다. 몰입형 증강현실 애플리케이션을 구축하는 경우 원격 서버를 쿼리하는 것은 바이바이블 옵션이 아닙니다. 

○모델은 대상 장치의 메모리 및 전력 제약 조건에서도 작동할 수 있을 정도로 충분히 작게 만들 수 있습니다. 

○가 가능한 한 높은 정확도를 얻는 것이 업무에 중요한 것은 아닙니다. 런타임 효율성과 정확성 사이에는 항상 균형이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델만큼 좋지 않은 모델을 출하해야 하는 경우가 많습니다. 

○입력 데이터는 엄격하게 민감하므로 원격 서버에서 해독할 수 없습니다. 

  

예를 들어, 스팸 탐지 모델은 최종 사용자의 스마트폰에서 채팅 앱의 일부로 실행되어야 합니다. 왜냐하면 메시지는 엔드 투 엔드로 암호화되어 원격으로 호스팅된 모델에서 전혀 읽을 수 없기 때문입니다. 나쁜 쿠키 탐지 모델은 엄격한 대기 시간 제약이 있어서 공장에서 실행해야 합니다. 다행히 이 경우 전력이나 공간 제약이 없기 때문에 GPU에서 실제로 모델을 실행할 수 있습니다. 

  

Keras 모델을 스마트폰이나 임베디드 기기에 배치하기 위해서는 Tensorflow Lite 솔루션을 사용해야 합니다. ARM64 기반 컴퓨터, 라즈베리 파이 또는 특정 마이크로컨트롤러뿐만 아니라 안드로이드 및 iOS 스마트폰에서 실행되는 장치 딥러닝 추론을 효율적으로 수행하기 위한 프레임워크입니다. Keras 모델을 텐서플로우 라이트 형식으로 바로 전환할 수 있는 컨버터를 포함합니다. 

#모델을 브라우저에 표시합니다. 

딥 러닝은 종종 브라우저 기반 또는 데스크톱 기반 자바스크립트 애플리케이션으로 사용됩니다. 애플리케이션이 REST API를 통해 원격 모델을 쿼리하는 것이 일반적으로 가능하지만, 대신 사용자의 컴퓨터에서 브라우저에서 직접 모델을 실행하도록 하는 주요 이점이 있을 수 있다. 

  

다음과 같은 경우 이 설정을 사용해야 합니다. 

○는 컴퓨팅을 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있습니다. 

○입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 합니다. 예를 들어, 우리의 스팸 탐지 프로젝트에서 채팅 앱의 웹 버전과 데스크톱 버전은 로컬에서 실행되는 모델을 사용해야 합니다. 

○애플리케이션에는 엄격한 지연 시간 제약이 있습니다. 최종 사용자의 노트북이나 스마트폰에서 실행되는 모델은 서버의 대형 GPU에서 실행되는 모델보다 속도가 느릴 수 있지만, 네트워크 왕복 100ms의 추가 시간이 없습니다. 

○모델이 다운로드된 후에도 연결 없이 계속 작동하려면 앱이 필요합니다. 캔 캐싱. 

  

물론, 당신의 모델이 당신의 노트북이나 스마트폰의 CPU, GPU, 램을 독점하지 않을 정도로 작을 경우에만 이 옵션을 사용해야 한다. 또한 전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 기밀을 유지해야 합니다. 훈련된 딥러닝 모델이 주어지면 훈련 데이터에 대한 일부 정보를 복구할 수 있다는 사실을 유념해야 한다. 즉, 훈련 모델이 민감한 데이터에 대해 훈련되었다면 공개하지 않는 것이 좋다. 

  

자바스크립트에 모델을 배치하기 위해 텐서플로우 생태계는 거의 모든 Keras API를 구현하는 딥러닝을 위한 자바스크립트 라이브러리인 tensorflow.js를 포함한다. 저장된 Keras 모델을 tensorflow.js로 가져와서 브라우저 기반 자바스크립트 앱이나 데스크톱 elctroct의 일부로 쿼리할 수 있다. 

#모형 최적화 

  

사용 가능한 전력 및 메모리에 대한 엄격한 제약이 있는 환경이나 지연 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 특히 중요합니다. tensorflow.js로 가져오거나 tensorflw lite로 내보내기 전에 항상 모델을 최적화해야 합니다. 

  

적용할 수 있는 두 가지 일반적인 최적화 기법이 있습니다. 

○가중치 가지치기: 무게 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아니다. 가장 중요한 항목만 유지함으로써 모델의 계층에서 매개변수 수를 크게 줄일 수 있습니다. 이를 통해 성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 공간을 줄일 수 있습니다. 적용할 가지치기 양을 조정함으로써 크기와 정확성 사이의 전통을 제어할 수 있습니다. 

○체중 정량화: 딥 러닝 모델은 단일 정밀 부동 체중을 사용하여 훈련된다. 그러나 가중치를 8비트 부호 정수로 양자화하여 4배 작지만 원래 모델의 정확도에 근접한 추론 전용 모델을 생성할 수 있다. 

텐서플로우 생태계는 Keras API와 깊이 통합된 가중치 가지치기 및 정량화 툴킷을 포함한다. 

# 야생에서 모델 모니터링  

추론 모형을 내보내고 애플리케이션에 통합한 다음, 모델이 예상한 대로 정확히 동작하는 생산 데이터에 대해 시운전을 수행했습니다. 유닛 테스트와 로깅 및 상태 모니터링 코드를 완벽하게 작성했습니다.이제 큰 빨간색 버튼을 누르고 프로덕션으로 배포하십시오. 

  

심지어 이것이 끝이 아니다. 모델을 배포한 후에는 모델의 동작을 계속 모니터링해야 합니다. 즉, enw 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용, business 메트릭에 대한 궁극적인 영향 등이 그것입니다. 

○는 새로운 음악 추천 시스템을 설치한 후 온라인 라디오에 대한 사용자 참여도를 높입니까, 낮춤입니까? 새로운 클릭률 예측 모델로 전환한 후 평균 광고 클릭률이 증가하였는가?모델 자체의 영향을 다른 모델과 분리하기 위해 무작위 A/B 테스트 사용을 고려한다. 

○가능한 경우 생산 데이터에 대한 모델의 예측에 대해 정기적으로 수동 감사를 실시하십시오. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있습니다. 수동으로 주석을 달 프로덕션 데이터의 일부를 보내고 수동으로 주석을 달 프로덕션 데이터를 비교하며 모델의 예측 사항을 새 주석과 비교할 수 있습니다. 예를 들어 이미지 검색 엔진과 잘못된 쿠키 플래그 지정 시스템에 대해 이 작업을 수행해야 합니다. 

# 모델 유지 관리 

마지막으로, 영원한 모델은 없다. 여러분은 이미 Diffit 개념에 대해 배웠습니다: 시간이 지남에 따라 생산 데이터의 특성이 변화하여 점차적으로 모델의 성능과 관련성을 저하시키고 음악 추천 시스템의 수명은 몇 주 안에 계산될 것입니다. 신용 카드 사기 탐지 시스템의 경우 며칠이 걸릴 수 있으며 이미지 검색 엔진의 경우 몇 년이 걸릴 수 있습니다. 
모델이 출시되는 즉시 모델을 대체할 차세대 모델을 교육할 준비를 해야 합니다.
○생산 데이터의 변화를 예측합니다. 새로운 기능을 사용할 수 있습니까? 라벨 세트를 확장해야 합니까, 그렇지 않으면 삭제해야 합니까?
○데이터를 계속 수집하고 주석을 달며 주석 파이프라인의 초과 근무를 계속 개선할 수 있습니다. 특히 현재 모형에 대해 분류하기 어려운 표본이 성능을 손상시키는 데 도움이 될 가능성이 가장 높은 표본은 성능 저하입니다.

이것으로 기억해야 할 많은 기계 학습의 보편적인 작업 흐름을 마무리합니다. 전문가가 되기 위해서는 시간과 경험이 필요하지만 걱정하지 마세요, 여러분은 이미 몇 장 전보다 훨씬 더 현명해졌습니다. 이제 여러분은 기계 학습 프로젝트에 수반되는 전체 스펙트럼의 큰 그림에 익숙해졌습니다. 이 책의 대부분은 모델 개발 부분에 초점을 맞추지만, 이제 전체 워크플로우의 일부분에 불과하다는 것을 알게 되었습니다. 항상 큰 그림을 명심하세요.
